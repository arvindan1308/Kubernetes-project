.# ğŸ›’ Global-Retail-Core
Enterprise Kubernetes Microservices Stack

Global-Retail-Core is a cloud-native microservices application deployed on Kubernetes.  
It consists of a Python Product API, a Node.js Order Service, and a MongoDB backend, all orchestrated with Kubernetes and exposed via an NGINX Ingress controller.

---

## ğŸ“ Repository Structure


â”œâ”€â”€ k8s-configuration/
â”‚   â”œâ”€â”€ namespace.yaml          # Logic isolation (production)
â”‚   â”œâ”€â”€ secret.yaml             # Encrypted DB credentials
â”‚   â”œâ”€â”€ configmap.yaml          # Application environment variables
â”‚   â”œâ”€â”€ database-deployment.yaml # MongoDB with PVC and ClusterIP
â”‚   â”œâ”€â”€ app-deployment.yaml      # Microservices (ReplicaSets)
â”‚   â””â”€â”€ ingress.yaml            # Path-based routing rules
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ product-api/            # Python Flask source & Dockerfile
â”‚   â””â”€â”€ order-service/          # Node.js source & Dockerfile
â””â”€â”€ README.md


---

## ğŸŒŸ Project Highlights

- Path-based routing using NGINX Ingress
- MongoDB persistence via Persistent Volume Claims (PVC)
- Prometheus and Grafana for cluster monitoring
- Local production-like setup using Minikube
- Docker image sideloading (no external registry)

---

## ğŸ—ï¸ Technical Stack

| Component | Technology |
|---------|------------|
| Orchestration | Kubernetes (Minikube) |
| Backend | Python (Flask), Node.js (Express) |
| Database | MongoDB |
| Ingress | NGINX |
| Monitoring | Prometheus, Grafana |

---

## ğŸš€ Setup & Deployment

### 1ï¸âƒ£ Start Minikube

```bash
minikube start --driver=docker --memory 4096
minikube addons enable ingress
minikube addons enable metrics-server

2ï¸âƒ£ Build & Load Images

docker build -t product-api:v1 ./services/product-api
docker build -t order-service:v1 ./services/order-service

minikube image load product-api:v1
minikube image load order-service:v1

3ï¸âƒ£ Deploy Kubernetes Resources

kubectl apply -f k8s-configuration/namespace.yaml 
kubectl apply -f k8s-configuration/secret.yaml 
kubectl apply -f k8s-configuration/configmap.yaml 
kubectl apply -f k8s-configuration/database-deployment.yaml 
kubectl apply -f k8s-configuration/app-deployment.yaml 
kubectl apply -f k8s-configuration/ingress.yaml
ğŸŒ Local Access
Start the tunnel:

minikube tunnel

Update /etc/hosts:
127.0.0.1 retail.local

ğŸ“Š Monitoring
Prometheus and Grafana are deployed using Helm.
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

helm install monitoring-stack prometheus-community/kube-prometheus-stack \
  -n monitoring --create-namespace

Access Grafana:
kubectl port-forward deployment/monitoring-stack-grafana 3000:3000 -n monitoring

Credentials
User: admin
Password: prom-operator

ğŸ” Validation
All application and system pods are running
MongoDB is using a persistent volume
Services are accessible through the Ingress controller
Prometheus is scraping cluster metrics

ğŸ› ï¸ Useful Commands
kubectl logs -l app=order-service -n production
kubectl rollout restart deployment <name> -n production
kubectl get ingress -n production
minikube image ls

ğŸš€ Deploying with Argo CD (GitOps)
Install Argo CD on Kubernetes (Minikube)
Create namespace:
kubectl create namespace argocd

Install Argo CD:
kubectl apply -n argocd \
  -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml

Verify pods:
kubectl get pods -n argocd
Wait until all are Running.

âœ… 2ï¸âƒ£ Access Argo CD UI
Port-forward the ArgoCD server:
kubectl port-forward svc/argocd-server -n argocd 8080:443
Open browser:
http://localhost:8080

âœ… 3ï¸âƒ£ Login to Argo CD
Get default admin password:
kubectl get secret argocd-initial-admin-secret -n argocd \
  -o jsonpath="{.data.password}" | base64 -d
Login:
* Username â†’ admin
* Password â†’ (value from above)

âœ… 4ï¸âƒ£ Create Application in Argo CD (UI)
1ï¸âƒ£ Click NEW APPâ€¨2ï¸âƒ£ Fill the fields:
Application Name
global-retail-core
Project
default
Repository URL
https://github.com/<your-username>/Kubernetes-project.git
Revision
main
Path
global-retail-core/k8s-configuration
Cluster
https://kubernetes.default.svc
Namespace
production
Click Create â†’ then click SYNC once to deploy.

â™»ï¸ 5ï¸âƒ£ Enable Auto Sync (Continuous Deployment)
Open the application in Argo CD â†’â€¨Go to App Details â†’ Edit â†’ Sync Policy
Enable:
âœ” Auto-Sync
âœ” Self-Heal
âœ” Prune
Save.

ğŸ¯ Result
Argo CD will now:â€¨âœ” Continuously monitor this Git repoâ€¨âœ” Detect Kubernetes manifest changesâ€¨âœ” Automatically deploy updatesâ€¨âœ” Heal drift if anything changes manuallyâ€¨âœ” Remove deleted resources
This makes the cluster always match Git state â€” true GitOps delivery.

ğŸ§ª Useful Commands
Check app:
argocd app list
Force sync:
argocd app sync global-retail-core
Refresh:
argocd app refresh global-retail-core